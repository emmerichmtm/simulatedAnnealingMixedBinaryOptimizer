# Mixedâ€‘Variable Simulatedâ€¯Annealing Optimizer

Python reference implementation of **simulated annealing (SA)** that can tackle decision vectors containing **both continuous and binary variables**.  The repository ships with two readyâ€‘toâ€‘run examples:

1. **Sumâ€‘ofâ€‘Squares minimisation** â€“ a simple benchmark.
2. **RosenbrockÂ + binaryâ€‘penalty** â€“ illustrates how to blend a classical continuous testâ€‘function with discrete logic constraints.

The core SA engine stays the same; you only swap in your own `objective()` definition.

---

## Features

* **Mixed variable types** â€“ flag each dimension as `"continuous"` or `"binary"`.
* **Easy objective plugâ€‘in** â€“ any Python callable that returns a scalar.
* **No gradients required** â€“ works on nonâ€‘smooth, nonâ€‘convex landscapes.
* **Autoâ€‘generated artefacts**

  * `convergence.png` â€“ objective value vs. iteration.
  * `optimum.txt` â€“ best vector (ASCII, one valueâ€¯/â€¯row).
* Clean, dependencyâ€‘light code (â‰ˆÂ 80Â LOC for engine + example script).

---

## Quickâ€‘Start (5Â min)

```bash
# 1â€¯. clone (or drop the files somewhere)
$ git clone https://github.com/yourâ€‘handle/saâ€‘mixed.git
$ cd saâ€‘mixed

# 2â€¯. create an isolated environment (optional but recommended)
$ python -m venv .venv
$ source .venv/bin/activate  # on Windows use .venv\Scripts\activate

# 3â€¯. install runtime deps (numpy & matplotlib only)
$ pip install -r requirements.txt

# 4â€¯. run a demo
$ python sa_mixed.py
```

After \~1Â s youâ€™ll see a convergence plot and two new files:

```text
./convergence.png   # 800â€‘step SA trace
./optimum.txt       # best vector found
```

---

## File Structure

```text
saâ€‘mixed/
â”œâ”€â”€ sa_engine.py       # the generic SA routine (imported by all examples)
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sa_sumSquares.py   # minimal 4â€‘var demo (2 cont + 2 bin)
â”‚   â””â”€â”€ sa_rosenbrock.py   # Rosenbrock + binary penalty example
â”œâ”€â”€ convergence.png    # produced after running a script
â”œâ”€â”€ optimum.txt        # produced after running a script
â””â”€â”€ README.md          # (this file)
```

> **Note**:  The example scripts write artefacts to the project root. Feel free to redirect paths.

---

## Customising the Optimiser

1. **Define your search space**

   ```python
   var_types = ["continuous", "binary", "continuous", ...]
   bounds    = np.array([[-5, 5], [0, 1], [â€‘3, 3], ...])
   init      = np.array([ 1.2 ,   0  ,  -0.7 , ...])
   ```
2. **Write an objective**

   ```python
   def objective(x: np.ndarray) -> float:
       # x is the full mixed vector â€“ use it however you like
       return some_scalar
   ```
3. **Tune hyperâ€‘parameters** (`n_iterations`, `step_size`, `temp`).

Thatâ€™s it â€“ call `simulated_annealing()`.

---

## Hyperâ€‘Parameter Cheatâ€‘Sheet

| Symbol         | Meaning                            | Typical range |
| -------------- | ---------------------------------- | ------------- |
| `n_iterations` | Search length                      | 10Â²Â â€“Â 10â´     |
| `step_size`    | Proposal scale (fraction of range) | 0.1Â â€“Â 0.5     |
| `temp`         | Initial temperature                | 5Â â€“Â 30        |

Lower `step_size` â†’ finer search but slower coverage.  Increase `temp` if the run gets stuck early.

---

## Requirements

* PythonÂ 3.8+
* numpy
* matplotlib
  *(all installable via `pip install -r requirements.txt`)*

---

## License

MIT â€“ do whatever you like, but no warranty.  See `LICENSE` for details.

---

## Citing or Learning More

If you use this template in academic work, please acknowledge with a short citation to this repository.  For background on simulated annealing consult:

* KirkpatrickÂ etâ€¯al., â€œOptimization by Simulated Annealingâ€, *Science*,Â 1983.
* ÄŒernÃ½, â€œThermodynamical Approach to the Traveling Salesman Problemâ€, 1985.

Happy optimization! ğŸ‰
